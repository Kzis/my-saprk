{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ttba-spark-lab2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO+KHbQYZSygysOZk9GuHYU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kzis/my-saprk/blob/main/ttba_spark_lab2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "YsMRmSDjFE67"
      },
      "outputs": [],
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q https://archive.apache.org/dist/spark/spark-2.4.1/spark-2.4.1-bin-hadoop2.7.tgz\n",
        "!tar xf spark-2.4.1-bin-hadoop2.7.tgz\n",
        "!pip install -q findspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-2.4.1-bin-hadoop2.7\""
      ],
      "metadata": {
        "id": "Gz5QPkauFI9z"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import findspark\n",
        "findspark.init()\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()"
      ],
      "metadata": {
        "id": "Ik03TQDMFJ7D"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession"
      ],
      "metadata": {
        "id": "GdcjskRxFLB_"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark = SparkSession.builder \\\n",
        "   .appName(\"Neural Network Model\") \\\n",
        "   .config(\"spark.executor.memory\", \"3gb\") \\\n",
        "   .getOrCreate()\n",
        "   \n",
        "sc = spark.sparkContext"
      ],
      "metadata": {
        "id": "dZ-4dt7eFMG5"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        },
        "id": "aPPcIyARFNMs",
        "outputId": "9707c185-b0ca-4e4b-fffd-bb097c0beea3"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<SparkContext master=local[*] appName=pyspark-shell>"
            ],
            "text/html": [
              "\n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://3168f331c39c:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v2.4.1</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>pyspark-shell</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lab 2"
      ],
      "metadata": {
        "id": "uSySPswCFlGs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import *\n",
        "\n",
        "# Define a dataset.\n",
        "\n",
        "df = sc.parallelize([\n",
        "    (10, '', 10000), (20, 'Female', 30000), (None, 'Male', 80000), (None, 'Male', 5000)\n",
        "]).toDF([\"age\", \"gender\", \"income\"])\n",
        "\n",
        "df.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "06ZFKHsqFnVm",
        "outputId": "e5e23bb5-efc1-4b8d-fc0e-31ac38d9697d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+------+------+\n",
            "| age|gender|income|\n",
            "+----+------+------+\n",
            "|  10|      | 10000|\n",
            "|  20|Female| 30000|\n",
            "|null|  Male| 80000|\n",
            "|null|  Male|  5000|\n",
            "+----+------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe().show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a5Z9TlMGFn0R",
        "outputId": "c4c00ce0-6d23-485e-9513-d5ad0f19b78e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+------------------+------+-----------------+\n",
            "|summary|               age|gender|           income|\n",
            "+-------+------------------+------+-----------------+\n",
            "|  count|                 2|     4|                4|\n",
            "|   mean|              15.0|  null|          31250.0|\n",
            "| stddev|7.0710678118654755|  null|34247.87098005753|\n",
            "|    min|                10|      |             5000|\n",
            "|    max|                20|  Male|            80000|\n",
            "+-------+------------------+------+-----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Cleansing: Null\n"
      ],
      "metadata": {
        "id": "2MGamSEwGfwl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Treat Null Value (None) with Average one.\n",
        "\n",
        "avg_age = df.na.drop().agg(avg(\"age\")).collect()[0][0]\n",
        "\n",
        "sparkf_replaceNull = udf(lambda x: avg_age if x == None else x)\n",
        "\n",
        "no_null_df = df.withColumn('age', sparkf_replaceNull(col('age')))\n",
        "\n",
        "no_null_df.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gb2LynwuFn4_",
        "outputId": "fc4deb91-1d91-4caa-8e2b-216295195240"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+------+------+\n",
            "| age|gender|income|\n",
            "+----+------+------+\n",
            "|  10|      | 10000|\n",
            "|  20|Female| 30000|\n",
            "|15.0|  Male| 80000|\n",
            "|15.0|  Male|  5000|\n",
            "+----+------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Cleansing: Empty Values\n"
      ],
      "metadata": {
        "id": "yRoCLfpdGip1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#  Treat Missing Value with Defined Values.\n",
        "\n",
        "from pyspark.sql.functions import *\n",
        "\n",
        "treat_missing = udf(lambda x: \"Male_Assume\" if x == \"\" else x)\n",
        "\n",
        "no_missing_df = no_null_df.withColumn('new_gender',treat_missing(no_null_df.gender))\n",
        "\n",
        "no_missing_df.show()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zxJnC18FGc_r",
        "outputId": "0f8c709e-25ba-4d5b-b3c6-4a889be970b4"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+------+------+-----------+\n",
            "| age|gender|income| new_gender|\n",
            "+----+------+------+-----------+\n",
            "|  10|      | 10000|Male_Assume|\n",
            "|  20|Female| 30000|     Female|\n",
            "|15.0|  Male| 80000|       Male|\n",
            "|15.0|  Male|  5000|       Male|\n",
            "+----+------+------+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Cleansing: Outliers (Business-oriented)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "pxXnvGEjGxSx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Treat Outliner with Remove one.\n",
        "\n",
        "no_outlier_df = no_missing_df.filter(col('income') >= 10000)\n",
        "\n",
        "no_outlier_df .show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Abe_LnU7Gy4s",
        "outputId": "1b13ba0a-5730-4055-8491-77bc28457366"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+------+------+-----------+\n",
            "| age|gender|income| new_gender|\n",
            "+----+------+------+-----------+\n",
            "|  10|      | 10000|Male_Assume|\n",
            "|  20|Female| 30000|     Female|\n",
            "|15.0|  Male| 80000|       Male|\n",
            "+----+------+------+-----------+\n",
            "\n"
          ]
        }
      ]
    }
  ]
}